\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Chapter 2 - Statistical Learning}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Overview (What is Statistical Learning)}{4}}
\@writefile{toc}{\contentsline {paragraph}{General}{4}}
\newlabel{eq:1}{{1}{4}}
\newlabel{eq:2}{{2}{4}}
\newlabel{eq:3}{{3}{4}}
\@writefile{toc}{\contentsline {paragraph}{Errors}{4}}
\@writefile{toc}{\contentsline {paragraph}{Inference}{4}}
\@writefile{toc}{\contentsline {paragraph}{parametric}{4}}
\@writefile{toc}{\contentsline {paragraph}{non-parametric}{5}}
\@writefile{toc}{\contentsline {paragraph}{supervised vs. unsupervised}{5}}
\@writefile{toc}{\contentsline {paragraph}{regression vs. classification}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Assessing Model Accuracy}{5}}
\@writefile{toc}{\contentsline {paragraph}{Quality of fit (fitness)}{5}}
\@writefile{toc}{\contentsline {paragraph}{bias vs. variance}{5}}
\@writefile{toc}{\contentsline {subparagraph}{variance}{6}}
\@writefile{toc}{\contentsline {subparagraph}{bias}{6}}
\@writefile{toc}{\contentsline {paragraph}{classification}{6}}
\@writefile{toc}{\contentsline {paragraph}{bayes classifier}{6}}
\@writefile{toc}{\contentsline {paragraph}{K-nearest neighbors}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Chapter 3 - Linear Regression}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Simple linear regression}{7}}
\@writefile{toc}{\contentsline {paragraph}{General}{7}}
\@writefile{toc}{\contentsline {paragraph}{Estimating the coefficients}{7}}
\@writefile{toc}{\contentsline {paragraph}{Accuracy of the coefficient estimates}{7}}
\@writefile{toc}{\contentsline {subparagraph}{true variance}{8}}
\@writefile{toc}{\contentsline {subparagraph}{estimated variance}{9}}
\@writefile{toc}{\contentsline {subparagraph}{hypothesis}{9}}
\@writefile{toc}{\contentsline {paragraph}{Accuracy of the model}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Multiple linear regression}{10}}
\@writefile{toc}{\contentsline {paragraph}{Estimating the coefficients}{10}}
\@writefile{toc}{\contentsline {paragraph}{Is there a relationship between response and predictors}{10}}
\@writefile{toc}{\contentsline {paragraph}{Deciding on important variables}{11}}
\@writefile{toc}{\contentsline {paragraph}{Model fit}{11}}
\@writefile{toc}{\contentsline {paragraph}{Prediction}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Other consideration in the regression model}{12}}
\@writefile{toc}{\contentsline {paragraph}{Qualitative predictors}{12}}
\@writefile{toc}{\contentsline {paragraph}{Removing additivity assumption}{13}}
\@writefile{toc}{\contentsline {paragraph}{Non-linear relationships}{13}}
\@writefile{toc}{\contentsline {paragraph}{Potential problems}{14}}
\@writefile{toc}{\contentsline {subparagraph}{Non-linearity of data}{14}}
\@writefile{toc}{\contentsline {subparagraph}{Correlation of error terms}{14}}
\@writefile{toc}{\contentsline {subparagraph}{Non-constant variance of error}{14}}
\@writefile{toc}{\contentsline {subparagraph}{Outliers}{14}}
\@writefile{toc}{\contentsline {subparagraph}{High leverage points}{15}}
\@writefile{toc}{\contentsline {subparagraph}{Collinearity}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Comparison of linear regression with KNN}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Chapter 4 - Classification}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Logistic regression}{17}}
\@writefile{toc}{\contentsline {paragraph}{logistic model}{17}}
\@writefile{toc}{\contentsline {paragraph}{Estimating the regression coefficients}{17}}
\@writefile{toc}{\contentsline {paragraph}{Making predictions}{18}}
\@writefile{toc}{\contentsline {paragraph}{Multiple logistic regression}{18}}
\@writefile{toc}{\contentsline {paragraph}{Logistic regression for more than two response classes}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Linear discriminant analysis}{18}}
\@writefile{toc}{\contentsline {paragraph}{Introduction}{18}}
\@writefile{toc}{\contentsline {paragraph}{Using Bayes' theorem for classification}{18}}
\@writefile{toc}{\contentsline {paragraph}{LDA using one predictor p=1}{19}}
\@writefile{toc}{\contentsline {paragraph}{LDA using multiple predictors p\(>\)1}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Quadratic discriminant analysis}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}A comparison of classification methods}{21}}
\@writefile{toc}{\contentsline {paragraph}{Logistic regression vs. LDA}{21}}
\@writefile{toc}{\contentsline {paragraph}{KNN}{21}}
\@writefile{toc}{\contentsline {paragraph}{QDA}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Chapter 5 - Resampling Methods}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cross-validation}{22}}
\@writefile{toc}{\contentsline {paragraph}{Training error rate vs. test error rate}{22}}
\@writefile{toc}{\contentsline {paragraph}{validation set approach}{22}}
\@writefile{toc}{\contentsline {paragraph}{Leave-one-out cross-validation (LOOCV)}{22}}
\@writefile{toc}{\contentsline {paragraph}{k-fold cross-validation}{23}}
\@writefile{toc}{\contentsline {paragraph}{Bias-variance trade-off for k-fold cross-validation}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The bootstrap}{24}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Chapter 6 - Linear Model Selection and Regularization}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Subset selection}{25}}
\@writefile{toc}{\contentsline {paragraph}{Best subset selection}{25}}
\@writefile{toc}{\contentsline {paragraph}{Forward stepwise selection}{25}}
\@writefile{toc}{\contentsline {paragraph}{Backward stepwise selection}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Shrinkage methods}{25}}
\@writefile{toc}{\contentsline {paragraph}{Ridge regression}{25}}
\@writefile{toc}{\contentsline {paragraph}{The lasso}{26}}
\@writefile{toc}{\contentsline {paragraph}{Alternative formulations}{26}}
\@writefile{toc}{\contentsline {paragraph}{Comparing the lasso and ridge regression}{27}}
\@writefile{toc}{\contentsline {paragraph}{Selecting the tuning parameter}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Dimension reduction methods}{27}}
\@writefile{toc}{\contentsline {paragraph}{Principal components approach}{27}}
\@writefile{toc}{\contentsline {subparagraph}{Principal components regression}{28}}
\@writefile{toc}{\contentsline {paragraph}{Partial least squares}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Considerations in high dimensions}{28}}
\@writefile{toc}{\contentsline {paragraph}{High dimensional data}{28}}
\@writefile{toc}{\contentsline {paragraph}{Interpreting results in high dimensions}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Chapter 7 - Moving Beyond Linearity}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Polynomial regression}{30}}
\@writefile{toc}{\contentsline {paragraph}{Straightforward extension to linear regression}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Step functions}{30}}
\@writefile{toc}{\contentsline {paragraph}{Allowing for local approximations}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Basis functions}{30}}
\@writefile{toc}{\contentsline {paragraph}{A more general approach}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Regression splines}{31}}
\@writefile{toc}{\contentsline {paragraph}{Piecewise polynomial}{31}}
\@writefile{toc}{\contentsline {paragraph}{Constraints and splines}{31}}
\@writefile{toc}{\contentsline {paragraph}{The spline basis representation}{31}}
\@writefile{toc}{\contentsline {paragraph}{Choosing the number and locations of the knots}{32}}
\@writefile{toc}{\contentsline {paragraph}{Comparison to polynomial regression}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Smoothing splines}{32}}
\@writefile{toc}{\contentsline {paragraph}{An overview of smoothing splines}{32}}
\@writefile{toc}{\contentsline {paragraph}{Choosing the smoothing parameter \(\lambda \)}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Local regression}{33}}
\@writefile{toc}{\contentsline {paragraph}{Using local data for prediction}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Generalized additive models}{33}}
\@writefile{toc}{\contentsline {paragraph}{GAMs for regression problems}{33}}
\@writefile{toc}{\contentsline {paragraph}{Pros and cons of GAMs}{33}}
\@writefile{toc}{\contentsline {paragraph}{CAMs for classification problems}{34}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Chapter 8 - Tree-based Methods}{35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}The basics of decision trees}{35}}
\@writefile{toc}{\contentsline {paragraph}{Regression trees}{35}}
\@writefile{toc}{\contentsline {paragraph}{Prediction via stratification of the feature space}{35}}
\@writefile{toc}{\contentsline {paragraph}{Tree pruning}{36}}
\@writefile{toc}{\contentsline {paragraph}{Classification trees}{36}}
\@writefile{toc}{\contentsline {paragraph}{Trees vs. linear models}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Bagging, random forests}{37}}
\@writefile{toc}{\contentsline {paragraph}{Bagging}{37}}
\@writefile{toc}{\contentsline {paragraph}{Random forests}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Chapter 9 - Support Vector Machines}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Maximal margin classifier}{39}}
\@writefile{toc}{\contentsline {paragraph}{What is a hyperplane?}{39}}
\@writefile{toc}{\contentsline {paragraph}{Classification using a separating hyperplane}{39}}
\@writefile{toc}{\contentsline {paragraph}{The maximal margin classifier}{39}}
\@writefile{toc}{\contentsline {paragraph}{The non-separable case}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Support vector classifier}{39}}
\@writefile{toc}{\contentsline {paragraph}{Details of the support vector classifier}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Support vector machines}{40}}
\@writefile{toc}{\contentsline {paragraph}{Classification with non-linear decision boundaries}{40}}
\@writefile{toc}{\contentsline {paragraph}{Support vector machine (SVM)}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}SVMs with more than one class}{42}}
\@writefile{toc}{\contentsline {paragraph}{One-versus-one}{42}}
\@writefile{toc}{\contentsline {paragraph}{One-versus-all}{42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Relationship to logistic regression}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Chapter 10 - Unsupervised Learning}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Principal Component Analysis}{43}}
\@writefile{toc}{\contentsline {paragraph}{PCA}{43}}
\@writefile{toc}{\contentsline {paragraph}{What are principal components?}{43}}
\@writefile{toc}{\contentsline {paragraph}{Scaling the variables}{44}}
\@writefile{toc}{\contentsline {paragraph}{Unique - up to a sign}{44}}
\@writefile{toc}{\contentsline {paragraph}{The proportion of variance}{44}}
\@writefile{toc}{\contentsline {paragraph}{How many principal components should be used?}{44}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Clustering Methods}{44}}
\@writefile{toc}{\contentsline {paragraph}{Clustering}{44}}
\@writefile{toc}{\contentsline {paragraph}{K-means clustering}{45}}
\@writefile{toc}{\contentsline {paragraph}{K-means clustering algorithm}{45}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical clustering}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Dendogram}}{46}}
\newlabel{fig:dendogram}{{1}{46}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical clustering algorithm}{46}}
\@writefile{toc}{\contentsline {paragraph}{Practical issues}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Important Formulas}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Linear regression}{48}}
\@writefile{toc}{\contentsline {paragraph}{Linear regression}{48}}
\@writefile{toc}{\contentsline {paragraph}{Multiple linear regression}{49}}
\@writefile{toc}{\contentsline {paragraph}{Other considerations}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Classification}{50}}
\@writefile{toc}{\contentsline {paragraph}{Logistic regression}{50}}
\@writefile{toc}{\contentsline {paragraph}{Linear discriminant analysis}{50}}
\@writefile{toc}{\contentsline {paragraph}{Quadratic discriminant analysis}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Resampling Methods}{51}}
\@writefile{toc}{\contentsline {paragraph}{Cross validation}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Linear Model Selection and Regularization}{51}}
\@writefile{toc}{\contentsline {paragraph}{Shrinkage methods}{51}}
\@writefile{toc}{\contentsline {paragraph}{Dimension reduction methods}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5}Moving Beyond Linearity}{52}}
\@writefile{toc}{\contentsline {paragraph}{Polynomial regression}{52}}
\@writefile{toc}{\contentsline {paragraph}{Step functions}{52}}
\@writefile{toc}{\contentsline {paragraph}{Regression splines}{52}}
\@writefile{toc}{\contentsline {paragraph}{Smoothing splines}{52}}
\@writefile{toc}{\contentsline {paragraph}{GAM}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.6}Tree-based Methods}{53}}
\@writefile{toc}{\contentsline {paragraph}{The basics of decision trees}{53}}
\@writefile{toc}{\contentsline {paragraph}{Bagging}{53}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.7}Support Vector Machines}{54}}
\@writefile{toc}{\contentsline {paragraph}{Maximal margin classifier}{54}}
\@writefile{toc}{\contentsline {paragraph}{Support Vector classifier}{54}}
\@writefile{toc}{\contentsline {paragraph}{Support Vector machines}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.8}Unsupervised Learning}{55}}
\@writefile{toc}{\contentsline {paragraph}{Principal Component Analysis}{55}}
\@writefile{toc}{\contentsline {paragraph}{K-means clustering}{55}}
\@writefile{toc}{\contentsline {paragraph}{Hierarchical clustering}{55}}
